["The unseen species problem is commonly referred to in ecology and deals with the estimation of the number of species represented in an ecosystem that were not observed by samples. It more specifically relates to how many new species would be discovered if more samples were taken in an ecosystem. The study of the unseen species problem was started in the early 1940s by Alexander Steven Corbet. He spent 2 years in British Malaya trapping butterflies and was curious how many new species he would discover if he spent another 2 years trapping. Many different estimation methods have been developed to determine how many new species would be discovered given more samples. The unseen species problem also applies more broadly, as the estimators can be used to estimate any new elements of a set not previously found in samples. An example of this is determining how many words William Shakespeare knew based on all of his written works. The unseen species problem can be broken down mathematically as follows:","If                         n                 {\\textstyle n}       independent samples are taken,                                    X                        n                             \u225c                    X                        1                             ,         \u2026         ,                    X                        n                                     {\\textstyle X^{n}\\triangleq X_{1},\\ldots ,X_{n}}      , and then if                         m                 {\\textstyle m}       more independent samples were taken, the number of unseen species that will be discovered by the additional samples is given by                        U         \u225c         U                    (                                       X                                n                                         ,                            X                                n                 +                 1                                               m                 +                 n                                                  )                  \u225c                    |                        {                            X                                n                 +                 1                                               m                 +                 n                                         }             \u2216             {                            X                                n                                         }                      |                          {\\displaystyle U\\triangleq U\\left(X^{n},X_{n+1}^{m+n}\\right)\\triangleq \\left|\\{X_{n+1}^{m+n}\\}\\smallsetminus \\{X^{n}\\}\\right|}    with                                    X                        n             +             1                                   m             +             n                             \u225c                    X                        n             +             1                             ,         \u2026         ,                    X                        n             +             m                                     {\\textstyle X_{n+1}^{m+n}\\triangleq X_{n+1},\\ldots ,X_{n+m}}       being the second set of                         m                 {\\displaystyle m}       samples.","In the early 1940s Alexander Steven Corbet spent 2 years in British Malaya trapping butterflies.[1] He kept track of how many species he observed, and how many members of each species were captured. For example, he captured only 2 members of 74 different species. When he returned to the United Kingdom, he approached statistician Ronald Fisher, and asked how many new species of butterflies he could expect to catch if he went trapping for another two years.[2] In essence, Corbet was asking how many species he observed zero times. Fisher responded with a simple estimation: for an additional 2 years of trapping, Corbet could expect to capture 75 new species. He did this using a simple summation (data provided by Orlitsky[2] in Table 1 below in the Example section):                        U         =         \u2212                    \u2211                        i             =             1                                   n                             (         \u2212         1                    )                        i                                        \u03c6                        i                             =         118         \u2212         74         +         44         \u2212         24         +         \u22ef         \u2212         12         +         6         =         75                 {\\displaystyle U=-\\sum _{i=1}^{n}(-1)^{i}\\varphi _{i}=118-74+44-24+\\cdots -12+6=75}    Here,                                    \u03c6                        i                                     {\\textstyle \\varphi _{i}}       corresponds to the number of individual species which were observed                         i                 {\\textstyle i}       times. Fisher's sum was later confirmed by Good\u2013Toulmin.[1]","To estimate the number of unseen species, let                         t         \u225c         m                    \/                  n                 {\\textstyle t\\triangleq m\/n}       be number of future samples (                        m                 {\\displaystyle m}      ) divided by the number of past samples (                        n                 {\\displaystyle n}      ), or                         m         =         t         n                 {\\displaystyle m=tn}      . Let                                    \u03c6                        i                                     {\\displaystyle \\varphi _{i}}       be the number of individual species observed                         i                 {\\displaystyle i}       times (for example, if there were 74 species of butterflies with 2 observed members throughout the  samples, then                                    \u03c6                        2                             =         74                 {\\displaystyle \\varphi _{2}=74}      ).","The Good\u2013Toulmin estimator was developed by I. J. Good and G. H. Toulmin in 1953.[3] The estimate of the unseen species based on the Good\u2013Toulmin estimator is given by                                   U                        G             T                             \u225c                    U                        G             T                                        (                                       X                                n                                         ,             t                      )                  \u225c         \u2212                    \u2211                        i             =             1                                   \u221e                             (         \u2212         t                    )                        i                                        \u03c6                        i                                     {\\displaystyle U^{GT}\\triangleq U^{GT}\\left(X^{n},t\\right)\\triangleq -\\sum _{i=1}^{\\infty }(-t)^{i}\\varphi _{i}}    The Good\u2013Toulmin Estimator has been shown to be a good estimate for values of                         t         \u2264         1                 {\\textstyle t\\leq 1}      . The Good\u2013Toulmin estimator also approximates that                        E         \u2061                                 (                                             U                                    G                   T                                               \u2212               U                          )                                   2                             \u2272         n                    t                        2                                     {\\displaystyle \\operatorname {E} \\left(U^{GT}-U\\right)^{2}\\lesssim nt^{2}}     This means that                                    U                        G             T                                     {\\textstyle U^{GT}}       estimates                         U                 {\\textstyle U}       to within                                                 n                             \u22c5         t                 {\\textstyle {\\sqrt {n}}\\cdot t}       as long as                         t         \u2264         1                 {\\textstyle t\\leq 1}      .\u00a0 However, for                         t         >         1                 {\\displaystyle t>1}      , the Good\u2013Toulmin estimator fails to capture accurate results. This is because, if                         t         >         1                 {\\displaystyle t>1}      ,                                    U                        G             T                                     {\\displaystyle U^{GT}}       increases by                         (         \u2212         t                    )                        i                                        \u03c6                        i                                     {\\displaystyle (-t)^{i}\\varphi _{i}}       for                         i                 {\\displaystyle i}       with                                    \u03c6                        i                             >         0                 {\\displaystyle \\varphi _{i}>0}      , meaning that if                                    \u03c6                        i                             >         0                 {\\displaystyle \\varphi _{i}>0}      ,                                    U                        G             T                                     {\\displaystyle U^{GT}}       grows super-linearly in                         t                 {\\displaystyle t}      , but                         U                 {\\displaystyle U}       can grow at most linearly with                         t                 {\\displaystyle t}      . Therefore, when                         t         >         1                 {\\displaystyle t>1}      ,                                    U                        G             T                                     {\\displaystyle U^{GT}}       grows faster than                         U                 {\\displaystyle U}       and does not approximate the true value.[2]","To compensate for this, Efron and Thisted[4] showed that a truncated Euler transform can also be a usable estimate:                                   U                        E             T                             \u225c                    \u2211                        i             =             1                                   n                                        h                        h                                   E             T                             \u22c5                    \u03c6                        i                                     {\\displaystyle U^{ET}\\triangleq \\sum _{i=1}^{n}h_{h}^{ET}\\cdot \\varphi _{i}}    with                                   h                        i                                   E             T                             \u225c         \u2212         (         \u2212         t                    )                        i                             \u22c5         Pr                    (                                       Bin                                         (                                k                 ,                                                         1                                            1                       +                       t                                                                                       )                          \u2265             i                      )                          {\\displaystyle h_{i}^{ET}\\triangleq -(-t)^{i}\\cdot \\Pr \\left({\\text{Bin}}\\left(k,{\\frac {1}{1+t}}\\right)\\geq i\\right)}    and                        Pr                    (                                       Bin                                         (                                k                 ,                                                         1                                            1                       +                       t                                                                                       )                          \u2265             i                      )                  =                                 {                                                                                     \u2211                                            j                       =                       i                                                                 k                                                                                                                                (                                                                       k                         j                                                                       )                                                                                                                                                       t                                                    k                           \u2212                           j                                                                                                (                         1                         +                         t                                                    )                                                        k                                                                                                                                                                        i                   \u2264                   k                   ,                                                                                   0                                                     i                   >                   k                                                                                               {\\displaystyle \\Pr \\left({\\text{Bin}}\\left(k,{\\frac {1}{1+t}}\\right)\\geq i\\right)={\\begin{cases}\\sum _{j=i}^{k}{k \\choose j}{\\frac {t^{k-j}}{(1+t)^{k}}}&i\\leq k,\\\\0&i>k\\end{cases}}}    where                         k                 {\\displaystyle k}       is the location chosen to truncate the Euler transform.","Similar to the approach by Efron and Thisted, Alon Orlitsky, Ananda Theertha Suresh, and Yihong Wu developed the smooth Good\u2013Toulmin estimator. They realized that the Good\u2013Toulmin estimator failed for  because of the exponential growth, and not its bias.[2] Therefore, they estimated the number of unseen species by truncating the series.                                   U                        \u2113                             \u225c         \u2212                    \u2211                        i             =             1                                   \u2113                             (         \u2212         t                    )                        i                                        \u03c6                        i                                     {\\displaystyle U^{\\ell }\\triangleq -\\sum _{i=1}^{\\ell }(-t)^{i}\\varphi _{i}}    Orlitsky, Suresh, and Wu also noted that for distributions with                         t         >         1                 {\\displaystyle t>1}      , the driving term in the summation estimate is the                                    \u2113                        th                                     {\\displaystyle \\ell ^{\\text{th}}}       term, regardless of which value of                         \u2113                 {\\displaystyle \\ell }       is chosen.[1] To solve this, they elected a random nonnegative integer                         L                 {\\displaystyle L}      , truncated the series at                         L                 {\\displaystyle L}      , and then took the average over a distribution about                         L                 {\\displaystyle L}      .[2] The resulting estimator is                                   U                        L                             =                    E                        L                             \u2061                    [                        \u2212                            \u2211                                i                 =                 1                                               L                                         (             \u2212             t                            )                                i                                                        \u03c6                                i                                                  ]                          {\\displaystyle U^{L}=\\operatorname {E} _{L}\\left[-\\sum _{i=1}^{L}(-t)^{i}\\varphi _{i}\\right]}    This method was chosen because the bias of                                    U                        \u2113                                     {\\displaystyle U^{\\ell }}       shifts signs due to the                         (         \u2212         t                    )                        i                                     {\\displaystyle (-t)^{i}}       coefficient. Averaging over a distribution of                         L                 {\\displaystyle L}       therefore reduces the bias. This means that the estimator can be written as the linear combination of the prevalence:[1]                                    U                        L                             =                    E                        L                             \u2061                    [                        \u2212                            \u2211                                i                 \u2265                 1                                         (             \u2212             t                            )                                i                                                        \u03c6                                i                                                                         1                                               i                 \u2264                 L                                                  ]                  =         \u2212                    \u2211                        i             \u2265             1                             (         \u2212         t                    )                        i                             Pr         (         L         \u2265         i         )                    \u03c6                        i                                     {\\displaystyle U^{L}=\\operatorname {E} _{L}\\left[-\\sum _{i\\geq 1}(-t)^{i}\\varphi _{i}\\mathbf {1} _{i\\leq L}\\right]=-\\sum _{i\\geq 1}(-t)^{i}\\Pr(L\\geq i)\\varphi _{i}}    Depending on the distribution of                         L                 {\\displaystyle L}       chosen, the results will vary. With this method, estimates can be made for                         t         \u221d         ln         \u2061         n                 {\\displaystyle t\\propto \\ln n}      , and this is the best possible.[2]","The species discovery curve can also be used. This curve relates the number of species found in an area as a function of the time. These curves can also be created by using estimators (such as the Good\u2013Toulmin estimator) and plotting the number of unseen species at each value for                         t                 {\\displaystyle t}      .[5]","A species discovery curve is always increasing, as there is never a sample that could decrease the number of discovered species. Furthermore, the species discovery curve is also decelerating; the more samples taken, the fewer unseen species are expected to be discovered. The species discovery curve will also never asymptote, as it is assumed that although the discovery rate might become infinitely slow, it will never actually stop.[5] Two common models for a species discovery curve are the logarithmic and the exponential function.","As an example, consider the data Corbet provided Fisher in the 1940s.[2] Using the Good\u2013Toulmin model, the number of unseen species is found using                        U         =         \u2212                    \u2211                        i             =             1                                   \u221e                             (         \u2212         t                    )                        i                                        \u03c6                        i                                     {\\displaystyle U=-\\sum _{i=1}^{\\infty }(-t)^{i}\\varphi _{i}}    This can then be used to create a relationship between                         t                 {\\displaystyle t}       and                         U                 {\\displaystyle U}      .","This relationship is shown in the plot below.","From the plot, it is seen that at                         t         =         1                 {\\displaystyle t=1}      , which was the value of                         t                 {\\displaystyle t}       that Corbet brought to Fisher, the resulting estimate of                         U                 {\\displaystyle U}       is 75, matching what Fisher found. This plot also acts as a species discovery curve for this ecosystem, and defines how many new species will be discovered as                         t                 {\\displaystyle t}       increases (and more samples are taken).","There are numerous uses for the predictive algorithm. Knowing that the estimators are accurate, it allows scientists to extrapolate accurately the results of polling people by a factor of 2. They can predict the number of unique answers based on the number of people that have answered similarly. The method can also be used to determine the extent of someone's knowledge. A prime example is determining how many unique words Shakespeare knew based on the written works we have today.","Based on research done by Thisted and Efron, of Shakespeare's known works, there are 884,647 total words.[4] The research also found that there are at total of                         N         =         864                 {\\displaystyle N=864}       different words that appear more than 100 times. Therefore, the total number of unique words was found to be 31,534.[4] Applying the Good\u2013Toulmin model, if an equal number of works by Shakespeare were discovered, then it is estimated that                                    U                        words                             \u2248         11         ,         460                 {\\displaystyle U^{\\text{words}}\\approx 11,460}       unique words would be found. The goal would be to derive                                    U                        words                                     {\\displaystyle U^{\\text{words}}}       for                         t         =         \u221e                 {\\displaystyle t=\\infty }      . Thisted and Efron estimate that                                    U                        words                             (         t         \u2192         \u221e         )         \u2248         35         ,         000                 {\\displaystyle U^{\\text{words}}(t\\rightarrow \\infty )\\approx 35,000}      , meaning that Shakespeare most likely knew over twice as many words as he actually used in all of his writings.[4]"]